{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMDM_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "uNoyfyngrNMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QpzoVECi1WRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bae101-2b87-418d-bec8-a3bdd31a91ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.18.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.53)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import optim\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import math"
      ],
      "metadata": {
        "id": "kpeiPPE3xJE2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to drive and reading data"
      ],
      "metadata": {
        "id": "23-MZEv4q1E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kt3sPUoqNagu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726dab48-af27-4e65-850b-1b542da7adcf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from TSV files\n",
        "training_data = pd.read_csv(\"/content/drive/My Drive/IITG/SMDM/Dataset/all_train.tsv\", sep = '\\t')\n",
        "validate_data = pd.read_csv(\"/content/drive/My Drive/IITG/SMDM/Dataset/all_validate.tsv\", sep = '\\t')\n",
        "testing_data = pd.read_csv(\"/content/drive/My Drive/IITG/SMDM/all_test_public.tsv\", sep = '\\t')\n",
        "print(testing_data.columns)"
      ],
      "metadata": {
        "id": "xhmu3YW7xHOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2042aee-25d6-4160-f455-443c1abdf4fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
            "       'author', 'clean_title', 'created_utc', 'domain', 'hasImage', 'id',\n",
            "       'image_url', 'linked_submission_id', 'num_comments', 'score',\n",
            "       'subreddit', 'title', 'upvote_ratio', '2_way_label', '3_way_label',\n",
            "       '6_way_label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing data"
      ],
      "metadata": {
        "id": "MAG8IiXKq9qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning data\n",
        "# ----- Training\n",
        "training_data.drop(training_data.columns.difference(['title','image_url','hasImage', 'clean_title','2_way_label','3_way_label','6_way_label']), 1, inplace=True)\n",
        "training_data = training_data[training_data['hasImage'] == True]\n",
        "training_data = training_data.dropna()\n",
        "\n",
        "validate_data.drop(training_data.columns.difference(['title','image_url','hasImage', 'clean_title','2_way_label','3_way_label','6_way_label']), 1, inplace=True)\n",
        "validate_data = training_data[training_data['hasImage'] == True]\n",
        "validate_data = training_data.dropna()\n",
        "\n",
        "testing_data.drop(training_data.columns.difference(['title','image_url','hasImage', 'clean_title','2_way_label','3_way_label','6_way_label']), 1, inplace=True)\n",
        "testing_data = training_data[training_data['hasImage'] == True]\n",
        "testing_data = training_data.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC1ch9FixVeC",
        "outputId": "6753cfc8-b06d-46af-853f-43e8a8257699"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of text\n",
        "text = training_data['clean_title'].tolist()\n",
        "\n",
        "print(text[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqI_1YCVzk8k",
        "outputId": "741ebb28-7e0a-4ed1-8195-a088155b2984"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my walgreens offbrand mucinex was engraved with the letters mucinex but in a different order', 'this concerned sink with a tiny hat', 'hackers leak emails from uae ambassador to us', 'puppy taking in the view', 'i found a face in my sheet music too', 'bride and groom exchange vows after fatal shooting at their wedding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Encoding"
      ],
      "metadata": {
        "id": "zuBe_mSMpAwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense_1 = nn.Linear(384, 512)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.model =  SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "    def forward(self,text):\n",
        "        embeddings = self.model.encode(text)\n",
        "        k = self.dense_1(torch.as_tensor(embeddings))\n",
        "        k = self.sig(k)\n",
        "        return k"
      ],
      "metadata": {
        "id": "yGwZwRVmF2Uh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying Text input"
      ],
      "metadata": {
        "id": "oLyM1GKZodzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = TextEncoding()\n",
        "text = ['hello How are you']\n",
        "\n",
        "dense_layout_output = t(text)\n",
        "print(dense_layout_output)\n",
        "dense_layout_output.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4bXRA7Gid8I",
        "outputId": "fa864045-5f93-47e6-f530-086fcf7e0aee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4979, 0.4677, 0.4011, 0.5140, 0.4900, 0.5424, 0.4844, 0.5645, 0.4595,\n",
            "         0.4993, 0.5136, 0.4640, 0.4441, 0.5909, 0.4272, 0.5654, 0.4965, 0.4363,\n",
            "         0.5656, 0.4211, 0.3966, 0.5014, 0.4847, 0.5266, 0.4632, 0.5142, 0.5552,\n",
            "         0.4266, 0.6011, 0.5327, 0.4863, 0.4790, 0.4919, 0.5262, 0.4649, 0.5501,\n",
            "         0.5131, 0.4569, 0.4724, 0.4484, 0.5942, 0.4412, 0.3970, 0.5881, 0.5475,\n",
            "         0.5542, 0.4652, 0.5276, 0.4892, 0.4856, 0.4813, 0.5117, 0.5163, 0.4719,\n",
            "         0.5222, 0.5191, 0.4970, 0.5659, 0.4303, 0.4694, 0.4377, 0.4874, 0.5510,\n",
            "         0.5442, 0.5418, 0.4503, 0.4825, 0.4648, 0.5520, 0.4859, 0.5863, 0.4112,\n",
            "         0.5207, 0.5173, 0.4692, 0.5028, 0.4906, 0.4595, 0.4946, 0.5176, 0.5374,\n",
            "         0.4553, 0.5537, 0.5571, 0.5042, 0.5039, 0.4176, 0.4814, 0.4605, 0.4670,\n",
            "         0.4865, 0.5625, 0.5183, 0.4363, 0.5449, 0.4881, 0.4220, 0.5424, 0.5869,\n",
            "         0.3837, 0.5025, 0.4202, 0.4857, 0.4862, 0.4957, 0.4883, 0.4382, 0.5057,\n",
            "         0.5616, 0.5000, 0.4535, 0.4795, 0.5152, 0.4569, 0.4880, 0.3451, 0.5352,\n",
            "         0.5082, 0.5187, 0.5739, 0.4589, 0.5009, 0.4768, 0.4516, 0.5620, 0.4113,\n",
            "         0.6535, 0.5272, 0.4482, 0.5303, 0.5208, 0.5038, 0.5476, 0.4064, 0.5065,\n",
            "         0.4687, 0.4760, 0.5857, 0.4710, 0.5020, 0.5568, 0.4892, 0.4485, 0.4632,\n",
            "         0.4639, 0.5719, 0.4690, 0.6029, 0.4950, 0.5469, 0.4884, 0.5206, 0.6027,\n",
            "         0.4208, 0.4006, 0.5453, 0.5160, 0.5197, 0.4376, 0.5227, 0.4958, 0.4788,\n",
            "         0.5213, 0.5244, 0.5822, 0.5265, 0.4587, 0.5112, 0.4581, 0.5776, 0.5041,\n",
            "         0.5092, 0.4239, 0.5049, 0.4745, 0.4878, 0.5090, 0.4784, 0.5676, 0.5528,\n",
            "         0.5726, 0.6206, 0.5227, 0.4548, 0.4651, 0.5020, 0.4050, 0.5894, 0.5061,\n",
            "         0.6108, 0.5179, 0.5359, 0.4667, 0.5381, 0.5005, 0.4952, 0.5000, 0.5431,\n",
            "         0.4612, 0.4757, 0.4747, 0.5458, 0.4767, 0.4505, 0.4569, 0.3982, 0.5230,\n",
            "         0.5266, 0.5309, 0.5113, 0.5285, 0.4579, 0.5108, 0.4453, 0.4684, 0.5651,\n",
            "         0.5237, 0.5486, 0.4450, 0.5927, 0.4488, 0.5428, 0.5157, 0.4704, 0.5082,\n",
            "         0.5924, 0.4512, 0.4426, 0.4803, 0.4786, 0.5220, 0.5133, 0.4823, 0.4838,\n",
            "         0.4916, 0.5097, 0.4512, 0.4142, 0.4889, 0.4492, 0.5142, 0.4583, 0.4796,\n",
            "         0.4061, 0.4673, 0.5469, 0.5937, 0.4694, 0.4909, 0.4363, 0.5571, 0.4732,\n",
            "         0.6004, 0.5094, 0.5439, 0.5152, 0.5003, 0.5115, 0.4804, 0.4402, 0.5588,\n",
            "         0.6067, 0.4864, 0.5132, 0.4548, 0.4359, 0.4859, 0.5079, 0.4031, 0.5285,\n",
            "         0.4454, 0.5333, 0.6055, 0.5376, 0.5502, 0.4457, 0.4983, 0.5567, 0.5371,\n",
            "         0.5521, 0.5129, 0.4830, 0.5021, 0.4527, 0.5532, 0.5919, 0.4951, 0.5551,\n",
            "         0.5204, 0.4912, 0.5806, 0.5337, 0.5299, 0.5399, 0.4931, 0.4642, 0.5325,\n",
            "         0.4083, 0.5115, 0.4703, 0.5602, 0.6014, 0.5213, 0.4663, 0.5422, 0.5158,\n",
            "         0.4670, 0.4904, 0.5453, 0.4235, 0.4651, 0.5338, 0.4425, 0.4576, 0.4167,\n",
            "         0.5483, 0.5314, 0.5465, 0.5628, 0.5576, 0.5098, 0.6006, 0.5085, 0.4404,\n",
            "         0.5393, 0.4750, 0.4896, 0.5013, 0.5013, 0.5817, 0.4734, 0.5578, 0.4974,\n",
            "         0.4650, 0.4873, 0.5279, 0.4382, 0.5163, 0.4663, 0.5230, 0.5073, 0.4494,\n",
            "         0.4658, 0.4661, 0.4493, 0.4407, 0.4543, 0.5078, 0.4737, 0.4741, 0.5244,\n",
            "         0.5389, 0.5183, 0.4656, 0.4486, 0.4208, 0.5430, 0.5020, 0.4194, 0.5668,\n",
            "         0.5206, 0.4398, 0.4584, 0.5118, 0.4511, 0.4138, 0.4327, 0.4352, 0.5119,\n",
            "         0.6373, 0.5836, 0.4692, 0.4719, 0.4947, 0.5236, 0.4696, 0.4398, 0.6197,\n",
            "         0.4816, 0.5675, 0.5294, 0.5040, 0.4600, 0.4743, 0.5471, 0.4908, 0.4902,\n",
            "         0.4011, 0.5092, 0.4690, 0.5156, 0.5141, 0.4903, 0.4651, 0.5245, 0.5342,\n",
            "         0.4504, 0.5697, 0.5034, 0.5152, 0.5145, 0.4987, 0.4737, 0.4176, 0.4818,\n",
            "         0.3907, 0.4814, 0.5902, 0.4663, 0.5461, 0.4643, 0.4948, 0.4562, 0.5186,\n",
            "         0.4917, 0.5030, 0.5986, 0.4969, 0.4860, 0.5001, 0.4428, 0.4621, 0.5530,\n",
            "         0.5650, 0.4683, 0.4039, 0.5356, 0.4327, 0.5249, 0.6009, 0.5488, 0.6230,\n",
            "         0.5149, 0.5117, 0.6047, 0.6085, 0.5685, 0.4207, 0.5443, 0.5016, 0.4493,\n",
            "         0.5655, 0.4938, 0.4606, 0.5393, 0.4799, 0.4222, 0.4233, 0.5179, 0.4623,\n",
            "         0.5195, 0.4482, 0.4967, 0.4959, 0.5222, 0.5293, 0.4343, 0.5976, 0.4444,\n",
            "         0.5218, 0.4483, 0.4903, 0.5206, 0.4870, 0.4354, 0.5833, 0.4869, 0.5426,\n",
            "         0.5131, 0.4794, 0.4784, 0.5144, 0.5533, 0.5758, 0.5951, 0.5423, 0.4613,\n",
            "         0.4787, 0.4317, 0.5045, 0.4231, 0.5330, 0.4559, 0.4792, 0.4344, 0.4591,\n",
            "         0.5139, 0.5208, 0.4843, 0.5186, 0.5620, 0.5193, 0.4353, 0.5253, 0.5002,\n",
            "         0.5201, 0.5237, 0.5101, 0.4962, 0.4831, 0.4846, 0.4861, 0.5749, 0.4938,\n",
            "         0.4934, 0.5783, 0.5067, 0.4652, 0.4780, 0.5625, 0.5498, 0.4295]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Encoding"
      ],
      "metadata": {
        "id": "MMocqAcbpGut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imodel = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n",
        "#imodel.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9dn53Ufo0JJ",
        "outputId": "2a97c6a7-063b-48ce-b2fb-6ae49cdd87f6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\t\t# Extract VGG-19 Feature Layers\n",
        "    self.features = list(model.features)\n",
        "    self.features = nn.Sequential(*self.features)\n",
        "\t\t# Extract VGG-19 Average Pooling Layer\n",
        "    self.pooling = model.avgpool\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.features(x)\n",
        "    out = self.pooling(out)\n",
        "    print(out.shape)\n",
        "    return out \n",
        " \n",
        "new_model = FeatureExtractor(imodel)"
      ],
      "metadata": {
        "id": "eDW9WSu7V55T"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the device to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "new_model = new_model.to(device)"
      ],
      "metadata": {
        "id": "PUbD2KfiWVwT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the feature vector of an Image\n",
        "filename = \"/content/drive/MyDrive/1000rows/images/1.jpg\"\n",
        "print(filename)\n",
        "filename = \"/content/drive/MyDrive/IITG/SMDM/Dataset/Images/images/\"+str(1)+\".jpg\"\n",
        "print(filename)\n",
        "#feature_vec = Img_feature(filename)\n",
        "#feature_vec.shape"
      ],
      "metadata": {
        "id": "BS_aDkymWguO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7e10e7-96b3-4aa5-8b2f-3ab945547e3e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/1000rows/images/1.jpg\n",
            "/content/drive/MyDrive/IITG/SMDM/Dataset/Images/images/1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "    def forward(self, filename):\n",
        "      return self.Img_feature(filename)  \n",
        "    \n",
        "    def Img_feature(self,filename):\n",
        "      img = Image.open(filename)\n",
        "      width,height = img.size\n",
        "      dim = min(width,height)\n",
        "      img.size\n",
        "      preprocess = transforms.Compose([   \n",
        "        transforms.CenterCrop(dim),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor()  \n",
        "      ])\n",
        "      img = preprocess(img)\n",
        "      img = img.reshape(1, 3, 224, 224)\n",
        "      img = img.to(device)\n",
        "    \n",
        "      feature = new_model(img)\n",
        "      return feature"
      ],
      "metadata": {
        "id": "eALsYDH-v4gy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_model = ImageModel()\n",
        "\n",
        "vgg_output = image_model(filename)\n",
        "print(vgg_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdAWkp4MvtpM",
        "outputId": "378d60ef-b5d2-4595-a95a-94ad36f9c755"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 7, 7])\n",
            "tensor([[[[0.2694, 1.1837, 0.5741,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.2834, 0.7161, 0.0000,  ..., 0.0000, 0.0000, 0.2228],\n",
            "          [0.0095, 0.0000, 0.0000,  ..., 0.2375, 2.6152, 2.3209],\n",
            "          ...,\n",
            "          [0.2354, 0.0000, 0.0000,  ..., 1.5213, 0.2500, 0.0000],\n",
            "          [0.7577, 0.0000, 0.0000,  ..., 0.6125, 0.0000, 0.0000],\n",
            "          [0.9607, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.1993, 0.9513, 0.2258,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0715, 0.4169, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.4345, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0365, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       grad_fn=<AdaptiveAvgPool2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Model"
      ],
      "metadata": {
        "id": "aTnwkBW1rY0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,in_channels = 3, n_filters = 3, filter_sizes = [3,4,5], embedding_dim = 384):\n",
        "       super().__init__()\n",
        "       # Input: Image - 224 x 224 x 3 \n",
        "       self.imageMap = ImageModel() \n",
        "       # Output:  128 x 128 x 256\n",
        "\n",
        "       # Input: Text  \n",
        "       self.embedding = TextEncoding()\n",
        "       # Output: 1 x 384\n",
        "         \n",
        "       self.flatten = nn.Flatten()\n",
        "       self.dense1 = nn.Linear(49, 128)\n",
        "       self.tanh = nn.Tanh()\n",
        "       self.dense2 = nn.Linear(128,64)\n",
        "       self.dense3 = nn.Linear(64,2)\n",
        "       self.conv = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)     \n",
        "    \n",
        "    def forward(self, text, filename):\n",
        "       I = self.imageMap(filename)\n",
        "       #print('Image map',I.shape)\n",
        "       k  = self.embedding(text)\n",
        "       #print('Text Encoding:',k.shape)\n",
        "       z = self.tiConv(I,k)\n",
        "       #print('Conv:',z.shape)\n",
        "       m = self.softmax2D(z)\n",
        "       #print('softmax:', m.shape)\n",
        "       I1 = self.elementWiseDot(m,I)\n",
        "       print('Dot:',I1.shape)\n",
        "       Ir = self.conv(I1)\n",
        "       print('Reduced:', Ir.shape)\n",
        "       flat = self.flatten(Ir)\n",
        "       #print('flatten:', flat.shape)\n",
        "       h = 1.7159 * self.tanh(self.dense2(self.dense1(flat)))\n",
        "       p = 1.7159 * self.tanh(self.dense3(h))\n",
        "       #return torch.argmax(p)\n",
        "       return p\n",
        "    \n",
        "    def elementWiseDot(self, m , I):\n",
        "       I1 = torch.zeros((1,512,7,7))\n",
        "       for i in range(len(I[0])):\n",
        "          I1[0, i, : , :] = m.mul(I[0, i, : , :])\n",
        "        \n",
        "       return I1\n",
        "\n",
        "\n",
        "    def tiConv(self, I, k):\n",
        "      output = torch.zeros((7,7))\n",
        "      for i in range(7):\n",
        "        for j in range(7):\n",
        "          output[i,j] = torch.dot(k[0], I[0,:,i,j])\n",
        "      \n",
        "      return output\n",
        "\n",
        "    def softmax2D(self, m):\n",
        "      sum = 0\n",
        "      for i in range(len(m)):\n",
        "        for j in range(len(m[0])):\n",
        "            sum = sum + math.e ** m[i,j]\n",
        "\n",
        "      v = torch.div(m, sum)\n",
        "      return v\n"
      ],
      "metadata": {
        "id": "y2_Nb6mL5IEZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "print(model(text, filename))\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "9ZibMEFFs2ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4bf3a1-c1e1-4d23-f94c-325d7dc3b952"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 7, 7])\n",
            "Dot: torch.Size([1, 512, 7, 7])\n",
            "Reduced: torch.Size([1, 1, 7, 7])\n",
            "tensor([[0.1057, 0.1116]], grad_fn=<MulBackward0>)\n",
            "Model(\n",
            "  (imageMap): ImageModel()\n",
            "  (embedding): TextEncoding(\n",
            "    (dense_1): Linear(in_features=384, out_features=512, bias=True)\n",
            "    (sig): Sigmoid()\n",
            "    (model): SentenceTransformer(\n",
            "      (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "      (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
            "    )\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dense1): Linear(in_features=49, out_features=128, bias=True)\n",
            "  (tanh): Tanh()\n",
            "  (dense2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (dense3): Linear(in_features=64, out_features=2, bias=True)\n",
            "  (conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "QIs3_9s9pMew"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function \n",
        "def train(num_epochs): \n",
        "    best_accuracy = 0.0 \n",
        "     \n",
        "    print(\"Begin training...\") \n",
        "    for epoch in range(num_epochs): \n",
        "        running_train_loss = 0.0 \n",
        "        running_accuracy = 0.0 \n",
        "        running_vall_loss = 0.0 \n",
        "        total = 0 \n",
        "        fullText = training_data['clean_title'].tolist()\n",
        "        # Training Loop \n",
        "        for i in range(len(training_data[0:10])):\n",
        "            text = []\n",
        "            text.append(fullText[i]) \n",
        "            #print('text', text)\n",
        "            imagefile = \"/content/drive/MyDrive/IITG/SMDM/Dataset/Images/images/\"+str(i+1)+\".jpg\"\n",
        "            output = training_data['2_way_label'].tolist()[i]\n",
        "            optimizer.zero_grad()   # zero the parameter gradients  \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predicted_outputs = model(text, imagefile)\n",
        "            print('predicted :', predicted_outputs)\n",
        "            o = []\n",
        "            o.append(output)\n",
        "            print('Output', torch.as_tensor(o))\n",
        "            train_loss = loss_fn(predicted_outputs, torch.as_tensor(o))\n",
        "            train_loss.backward()\n",
        "            print(model.dense3.weight.grad)\n",
        "            optimizer.step()\n",
        "            running_train_loss +=train_loss.item()\n",
        " \n",
        "        # Calculate training loss value \n",
        "        train_loss_value = running_train_loss/len(training_data) \n",
        "        \n",
        "        # Validation Loop \n",
        "        with torch.no_grad(): \n",
        "            model.eval() \n",
        "            for i in range(len(validate_data[0:10])): \n",
        "               text = []\n",
        "               text.append(validate_data['clean_title'].tolist()[i])   # get the input and real species as outputs; data is a list of [inputs, outputs] \n",
        "               imagefile =  \"/content/drive/MyDrive/IITG/SMDM/Dataset/Images/images/\"+str(i+1)+\".jpg\"  #images of validation data\n",
        "               output = validate_data['2_way_label'].tolist()[i]\n",
        "               o = []\n",
        "               o.append(output)\n",
        "               predicted_outputs = model(text, imagefile)\n",
        "               val_loss = loss_fn(predicted_outputs, torch.as_tensor(o)) \n",
        "               \n",
        "               # The label with the highest value will be our prediction \n",
        "               _, predicted = torch.max(predicted_outputs, 1) \n",
        "               running_vall_loss += val_loss.item()  \n",
        "               total += 1\n",
        "               running_accuracy += (predicted == output).sum().item() \n",
        " \n",
        "        # Calculate validation loss value \n",
        "        val_loss_value = running_vall_loss/len(validate_data) \n",
        "        \n",
        "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
        "        accuracy = (100 * running_accuracy / total)     \n",
        "          \n",
        "        # Print the statistics of the epoch \n",
        "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"
      ],
      "metadata": {
        "id": "pP_wes3H_CsO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "train(2)"
      ],
      "metadata": {
        "id": "GoAUCPY-sFAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "630831d4-cfe7-4cda-d495-e63db606e7b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training...\n",
            "torch.Size([1, 512, 7, 7])\n",
            "Dot: torch.Size([1, 512, 7, 7])\n",
            "Reduced: torch.Size([1, 1, 7, 7])\n",
            "predicted : tensor([[nan, nan]], grad_fn=<MulBackward0>)\n",
            "Output tensor([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py:175: UserWarning: Error detected in LogSoftmaxBackward0. Traceback of forward call that caused the error:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-50-4bc54e4b60e9>\", line 2, in <module>\n",
            "    train(2)\n",
            "  File \"<ipython-input-47-0c2fd6d9cd79>\", line 27, in train\n",
            "    train_loss = loss_fn(predicted_outputs, torch.as_tensor(o))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\", line 1165, in forward\n",
            "    label_smoothing=self.label_smoothing)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 2996, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
            " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
            "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4bc54e4b60e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-0c2fd6d9cd79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Function 'LogSoftmaxBackward0' returned nan values in its 0th output."
          ]
        }
      ]
    }
  ]
}